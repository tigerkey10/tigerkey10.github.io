{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionV3 모델로 시도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7993 images belonging to 20 classes.\n",
      "Found 1999 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "# 이미지 데이터 전처리 # 데이터 증식 사용\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.5,\n",
    "    zoom_range=[0.8, 2.0],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip = True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # 검증데이터는 증식하지 않는다.\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/kibeomkim/Desktop/flickr/train', \n",
    "    target_size=(150, 150),\n",
    "    batch_size=5, \n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    '/Users/kibeomkim/Desktop/flickr/test',\n",
    "    target_size=(150,150),\n",
    "    batch_size=5,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 21:35:44.820962: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1589/1590 [============================>.] - ETA: 0s - loss: 2.8503 - categorical_accuracy: 0.2082"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 21:36:30.852532: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1590/1590 [==============================] - 56s 34ms/step - loss: 2.8508 - categorical_accuracy: 0.2084 - val_loss: 2.4605 - val_categorical_accuracy: 0.2647\n",
      "Epoch 2/15\n",
      "1590/1590 [==============================] - 53s 34ms/step - loss: 2.4712 - categorical_accuracy: 0.2613 - val_loss: 2.3883 - val_categorical_accuracy: 0.2877\n",
      "Epoch 3/15\n",
      "1590/1590 [==============================] - 54s 34ms/step - loss: 2.4446 - categorical_accuracy: 0.2826 - val_loss: 2.4386 - val_categorical_accuracy: 0.3018\n",
      "Epoch 4/15\n",
      "1590/1590 [==============================] - 53s 33ms/step - loss: 2.4095 - categorical_accuracy: 0.2879 - val_loss: 2.6577 - val_categorical_accuracy: 0.2436\n",
      "Epoch 5/15\n",
      "1590/1590 [==============================] - 54s 34ms/step - loss: 2.4352 - categorical_accuracy: 0.2895 - val_loss: 2.7581 - val_categorical_accuracy: 0.2707\n",
      "Epoch 6/15\n",
      "1590/1590 [==============================] - 54s 34ms/step - loss: 2.4294 - categorical_accuracy: 0.2909 - val_loss: 2.6832 - val_categorical_accuracy: 0.2692\n",
      "Epoch 7/15\n",
      "1590/1590 [==============================] - 53s 33ms/step - loss: 2.4417 - categorical_accuracy: 0.2811 - val_loss: 2.4879 - val_categorical_accuracy: 0.2847\n",
      "Epoch 8/15\n",
      "1590/1590 [==============================] - 54s 34ms/step - loss: 2.4370 - categorical_accuracy: 0.2852 - val_loss: 2.6968 - val_categorical_accuracy: 0.2842\n",
      "Epoch 9/15\n",
      "1590/1590 [==============================] - 54s 34ms/step - loss: 2.4749 - categorical_accuracy: 0.2807 - val_loss: 2.4966 - val_categorical_accuracy: 0.2571\n",
      "Epoch 10/15\n",
      "1590/1590 [==============================] - 54s 34ms/step - loss: 2.4864 - categorical_accuracy: 0.2759 - val_loss: 2.6262 - val_categorical_accuracy: 0.2586\n",
      "Epoch 11/15\n",
      "1590/1590 [==============================] - 54s 34ms/step - loss: 2.4855 - categorical_accuracy: 0.2758 - val_loss: 2.6642 - val_categorical_accuracy: 0.2617\n",
      "Epoch 12/15\n",
      "1590/1590 [==============================] - 55s 34ms/step - loss: 2.5279 - categorical_accuracy: 0.2648 - val_loss: 2.7042 - val_categorical_accuracy: 0.2622\n",
      "Epoch 13/15\n",
      "1590/1590 [==============================] - 54s 34ms/step - loss: 2.5152 - categorical_accuracy: 0.2721 - val_loss: 3.1025 - val_categorical_accuracy: 0.2386\n",
      "Epoch 14/15\n",
      "1590/1590 [==============================] - 54s 34ms/step - loss: 2.5341 - categorical_accuracy: 0.2627 - val_loss: 2.7017 - val_categorical_accuracy: 0.2371\n",
      "Epoch 15/15\n",
      "1590/1590 [==============================] - 54s 34ms/step - loss: 2.5808 - categorical_accuracy: 0.2509 - val_loss: 2.7764 - val_categorical_accuracy: 0.2085\n",
      "0 input_5\n",
      "1 conv2d_376\n",
      "2 batch_normalization_376\n",
      "3 activation_376\n",
      "4 conv2d_377\n",
      "5 batch_normalization_377\n",
      "6 activation_377\n",
      "7 conv2d_378\n",
      "8 batch_normalization_378\n",
      "9 activation_378\n",
      "10 max_pooling2d_16\n",
      "11 conv2d_379\n",
      "12 batch_normalization_379\n",
      "13 activation_379\n",
      "14 conv2d_380\n",
      "15 batch_normalization_380\n",
      "16 activation_380\n",
      "17 max_pooling2d_17\n",
      "18 conv2d_384\n",
      "19 batch_normalization_384\n",
      "20 activation_384\n",
      "21 conv2d_382\n",
      "22 conv2d_385\n",
      "23 batch_normalization_382\n",
      "24 batch_normalization_385\n",
      "25 activation_382\n",
      "26 activation_385\n",
      "27 average_pooling2d_36\n",
      "28 conv2d_381\n",
      "29 conv2d_383\n",
      "30 conv2d_386\n",
      "31 conv2d_387\n",
      "32 batch_normalization_381\n",
      "33 batch_normalization_383\n",
      "34 batch_normalization_386\n",
      "35 batch_normalization_387\n",
      "36 activation_381\n",
      "37 activation_383\n",
      "38 activation_386\n",
      "39 activation_387\n",
      "40 mixed0\n",
      "41 conv2d_391\n",
      "42 batch_normalization_391\n",
      "43 activation_391\n",
      "44 conv2d_389\n",
      "45 conv2d_392\n",
      "46 batch_normalization_389\n",
      "47 batch_normalization_392\n",
      "48 activation_389\n",
      "49 activation_392\n",
      "50 average_pooling2d_37\n",
      "51 conv2d_388\n",
      "52 conv2d_390\n",
      "53 conv2d_393\n",
      "54 conv2d_394\n",
      "55 batch_normalization_388\n",
      "56 batch_normalization_390\n",
      "57 batch_normalization_393\n",
      "58 batch_normalization_394\n",
      "59 activation_388\n",
      "60 activation_390\n",
      "61 activation_393\n",
      "62 activation_394\n",
      "63 mixed1\n",
      "64 conv2d_398\n",
      "65 batch_normalization_398\n",
      "66 activation_398\n",
      "67 conv2d_396\n",
      "68 conv2d_399\n",
      "69 batch_normalization_396\n",
      "70 batch_normalization_399\n",
      "71 activation_396\n",
      "72 activation_399\n",
      "73 average_pooling2d_38\n",
      "74 conv2d_395\n",
      "75 conv2d_397\n",
      "76 conv2d_400\n",
      "77 conv2d_401\n",
      "78 batch_normalization_395\n",
      "79 batch_normalization_397\n",
      "80 batch_normalization_400\n",
      "81 batch_normalization_401\n",
      "82 activation_395\n",
      "83 activation_397\n",
      "84 activation_400\n",
      "85 activation_401\n",
      "86 mixed2\n",
      "87 conv2d_403\n",
      "88 batch_normalization_403\n",
      "89 activation_403\n",
      "90 conv2d_404\n",
      "91 batch_normalization_404\n",
      "92 activation_404\n",
      "93 conv2d_402\n",
      "94 conv2d_405\n",
      "95 batch_normalization_402\n",
      "96 batch_normalization_405\n",
      "97 activation_402\n",
      "98 activation_405\n",
      "99 max_pooling2d_18\n",
      "100 mixed3\n",
      "101 conv2d_410\n",
      "102 batch_normalization_410\n",
      "103 activation_410\n",
      "104 conv2d_411\n",
      "105 batch_normalization_411\n",
      "106 activation_411\n",
      "107 conv2d_407\n",
      "108 conv2d_412\n",
      "109 batch_normalization_407\n",
      "110 batch_normalization_412\n",
      "111 activation_407\n",
      "112 activation_412\n",
      "113 conv2d_408\n",
      "114 conv2d_413\n",
      "115 batch_normalization_408\n",
      "116 batch_normalization_413\n",
      "117 activation_408\n",
      "118 activation_413\n",
      "119 average_pooling2d_39\n",
      "120 conv2d_406\n",
      "121 conv2d_409\n",
      "122 conv2d_414\n",
      "123 conv2d_415\n",
      "124 batch_normalization_406\n",
      "125 batch_normalization_409\n",
      "126 batch_normalization_414\n",
      "127 batch_normalization_415\n",
      "128 activation_406\n",
      "129 activation_409\n",
      "130 activation_414\n",
      "131 activation_415\n",
      "132 mixed4\n",
      "133 conv2d_420\n",
      "134 batch_normalization_420\n",
      "135 activation_420\n",
      "136 conv2d_421\n",
      "137 batch_normalization_421\n",
      "138 activation_421\n",
      "139 conv2d_417\n",
      "140 conv2d_422\n",
      "141 batch_normalization_417\n",
      "142 batch_normalization_422\n",
      "143 activation_417\n",
      "144 activation_422\n",
      "145 conv2d_418\n",
      "146 conv2d_423\n",
      "147 batch_normalization_418\n",
      "148 batch_normalization_423\n",
      "149 activation_418\n",
      "150 activation_423\n",
      "151 average_pooling2d_40\n",
      "152 conv2d_416\n",
      "153 conv2d_419\n",
      "154 conv2d_424\n",
      "155 conv2d_425\n",
      "156 batch_normalization_416\n",
      "157 batch_normalization_419\n",
      "158 batch_normalization_424\n",
      "159 batch_normalization_425\n",
      "160 activation_416\n",
      "161 activation_419\n",
      "162 activation_424\n",
      "163 activation_425\n",
      "164 mixed5\n",
      "165 conv2d_430\n",
      "166 batch_normalization_430\n",
      "167 activation_430\n",
      "168 conv2d_431\n",
      "169 batch_normalization_431\n",
      "170 activation_431\n",
      "171 conv2d_427\n",
      "172 conv2d_432\n",
      "173 batch_normalization_427\n",
      "174 batch_normalization_432\n",
      "175 activation_427\n",
      "176 activation_432\n",
      "177 conv2d_428\n",
      "178 conv2d_433\n",
      "179 batch_normalization_428\n",
      "180 batch_normalization_433\n",
      "181 activation_428\n",
      "182 activation_433\n",
      "183 average_pooling2d_41\n",
      "184 conv2d_426\n",
      "185 conv2d_429\n",
      "186 conv2d_434\n",
      "187 conv2d_435\n",
      "188 batch_normalization_426\n",
      "189 batch_normalization_429\n",
      "190 batch_normalization_434\n",
      "191 batch_normalization_435\n",
      "192 activation_426\n",
      "193 activation_429\n",
      "194 activation_434\n",
      "195 activation_435\n",
      "196 mixed6\n",
      "197 conv2d_440\n",
      "198 batch_normalization_440\n",
      "199 activation_440\n",
      "200 conv2d_441\n",
      "201 batch_normalization_441\n",
      "202 activation_441\n",
      "203 conv2d_437\n",
      "204 conv2d_442\n",
      "205 batch_normalization_437\n",
      "206 batch_normalization_442\n",
      "207 activation_437\n",
      "208 activation_442\n",
      "209 conv2d_438\n",
      "210 conv2d_443\n",
      "211 batch_normalization_438\n",
      "212 batch_normalization_443\n",
      "213 activation_438\n",
      "214 activation_443\n",
      "215 average_pooling2d_42\n",
      "216 conv2d_436\n",
      "217 conv2d_439\n",
      "218 conv2d_444\n",
      "219 conv2d_445\n",
      "220 batch_normalization_436\n",
      "221 batch_normalization_439\n",
      "222 batch_normalization_444\n",
      "223 batch_normalization_445\n",
      "224 activation_436\n",
      "225 activation_439\n",
      "226 activation_444\n",
      "227 activation_445\n",
      "228 mixed7\n",
      "229 conv2d_448\n",
      "230 batch_normalization_448\n",
      "231 activation_448\n",
      "232 conv2d_449\n",
      "233 batch_normalization_449\n",
      "234 activation_449\n",
      "235 conv2d_446\n",
      "236 conv2d_450\n",
      "237 batch_normalization_446\n",
      "238 batch_normalization_450\n",
      "239 activation_446\n",
      "240 activation_450\n",
      "241 conv2d_447\n",
      "242 conv2d_451\n",
      "243 batch_normalization_447\n",
      "244 batch_normalization_451\n",
      "245 activation_447\n",
      "246 activation_451\n",
      "247 max_pooling2d_19\n",
      "248 mixed8\n",
      "249 conv2d_456\n",
      "250 batch_normalization_456\n",
      "251 activation_456\n",
      "252 conv2d_453\n",
      "253 conv2d_457\n",
      "254 batch_normalization_453\n",
      "255 batch_normalization_457\n",
      "256 activation_453\n",
      "257 activation_457\n",
      "258 conv2d_454\n",
      "259 conv2d_455\n",
      "260 conv2d_458\n",
      "261 conv2d_459\n",
      "262 average_pooling2d_43\n",
      "263 conv2d_452\n",
      "264 batch_normalization_454\n",
      "265 batch_normalization_455\n",
      "266 batch_normalization_458\n",
      "267 batch_normalization_459\n",
      "268 conv2d_460\n",
      "269 batch_normalization_452\n",
      "270 activation_454\n",
      "271 activation_455\n",
      "272 activation_458\n",
      "273 activation_459\n",
      "274 batch_normalization_460\n",
      "275 activation_452\n",
      "276 mixed9_0\n",
      "277 concatenate_8\n",
      "278 activation_460\n",
      "279 mixed9\n",
      "280 conv2d_465\n",
      "281 batch_normalization_465\n",
      "282 activation_465\n",
      "283 conv2d_462\n",
      "284 conv2d_466\n",
      "285 batch_normalization_462\n",
      "286 batch_normalization_466\n",
      "287 activation_462\n",
      "288 activation_466\n",
      "289 conv2d_463\n",
      "290 conv2d_464\n",
      "291 conv2d_467\n",
      "292 conv2d_468\n",
      "293 average_pooling2d_44\n",
      "294 conv2d_461\n",
      "295 batch_normalization_463\n",
      "296 batch_normalization_464\n",
      "297 batch_normalization_467\n",
      "298 batch_normalization_468\n",
      "299 conv2d_469\n",
      "300 batch_normalization_461\n",
      "301 activation_463\n",
      "302 activation_464\n",
      "303 activation_467\n",
      "304 activation_468\n",
      "305 batch_normalization_469\n",
      "306 activation_461\n",
      "307 mixed9_1\n",
      "308 concatenate_9\n",
      "309 activation_469\n",
      "310 mixed10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`tf.compat.v1.keras` Optimizer (<keras.optimizer_v1.SGD object at 0x2b57471c0>) is not supported when eager execution is enabled. Use a `tf.keras` Optimizer instead, or disable eager execution.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d4/2tkf12c121j9pm73mz8hvsd40000gn/T/ipykernel_62811/1943111878.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# 낮은 학습 속도로 세팅된 SGD를 사용합니다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m model.compile(\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_validate_compile\u001b[0;34m(self, optimizer, metrics, **kwargs)\u001b[0m\n\u001b[1;32m   2763\u001b[0m         \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2764\u001b[0m         for opt in tf.nest.flatten(optimizer)):\n\u001b[0;32m-> 2765\u001b[0;31m       raise ValueError(\n\u001b[0m\u001b[1;32m   2766\u001b[0m           \u001b[0;34mf'`tf.compat.v1.keras` Optimizer ({optimizer}) is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2767\u001b[0m           \u001b[0;34m'not supported when eager execution is enabled. Use a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `tf.compat.v1.keras` Optimizer (<keras.optimizer_v1.SGD object at 0x2b57471c0>) is not supported when eager execution is enabled. Use a `tf.keras` Optimizer instead, or disable eager execution."
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.optimizer_v1 import sgd\n",
    "\n",
    "\n",
    "# 합성곱 기반 층 - 이미지넷 분류기 제거 \n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# 합성곱 기반 층 출력 \n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# 완전연결분류기에 합성곱 기반 층 출력 주입\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# 분류결과 출력 층 \n",
    "predictions = Dense(20, activation='softmax')(x)\n",
    "\n",
    "# 모델 구축\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# 합성곱 기반 층 가중치 동결 \n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 모델 컴파일 \n",
    "model.compile(\n",
    "    optimizer='rmsprop', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "# 모델 학습 \n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 1590, \n",
    "    epochs=15,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps= 399, \n",
    "    #verbose=2,\n",
    "    #callbacks=callbacks_list \n",
    ")\n",
    "\n",
    "# -------- 미세조정 ---------\n",
    "\n",
    "# 이 시점에서 상위 레이어들은 충분히 학습이 되었기에,\n",
    "# inception V3의 콘볼루션 레이어에 대한 파인튜닝을 시작합니다 \n",
    "# 가장 밑 N개의 레이어를 고정하고 나머지 상위 레이어를 학습시킵니다\n",
    "\n",
    "# 레이어 이름과 레이어 인덱스를 시각화하여\n",
    "# 얼마나 많은 레이어를 고정시켜야 하는지 확인합니다:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# 가장 상위 2개의 inception 블록을 학습하기로 고릅니다,\n",
    "# 다시 말하면 첫 249개의 레이어는 고정시키고 나머지는 고정하지 않습니다:\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# 이러한 수정사항이 효과를 내려면 모델을 다시 컴파일해야 합니다\n",
    "# 낮은 학습 속도로 세팅된 SGD를 사용합니다\n",
    "\n",
    "model.compile(\n",
    "    optimizer=sgd(lr=0.0001, momentum=0.9), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "# 다시 한 번 모델을 학습시킵니다\n",
    "# (이번엔 상위 2개의 inception 블록을 상위의 밀집 레이어들과 함께 파인튜닝합니다)\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 1590, \n",
    "    epochs=100,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps= 399, \n",
    "    #verbose=2,\n",
    "    #callbacks=callbacks_list \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 21:52:39.791444: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1590/1590 [==============================] - ETA: 0s - loss: 2.6144 - categorical_accuracy: 0.1960"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 21:53:51.269098: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1590/1590 [==============================] - 83s 49ms/step - loss: 2.6144 - categorical_accuracy: 0.1960 - val_loss: 3.0382 - val_categorical_accuracy: 0.2511\n",
      "Epoch 2/100\n",
      "1590/1590 [==============================] - 79s 50ms/step - loss: 2.4491 - categorical_accuracy: 0.2554 - val_loss: 2.8487 - val_categorical_accuracy: 0.3148\n",
      "Epoch 3/100\n",
      "1590/1590 [==============================] - 79s 50ms/step - loss: 2.3760 - categorical_accuracy: 0.2724 - val_loss: 2.7016 - val_categorical_accuracy: 0.3258\n",
      "Epoch 4/100\n",
      "1590/1590 [==============================] - 80s 50ms/step - loss: 2.2977 - categorical_accuracy: 0.2952 - val_loss: 2.8163 - val_categorical_accuracy: 0.3183\n",
      "Epoch 5/100\n",
      "1590/1590 [==============================] - 79s 50ms/step - loss: 2.2365 - categorical_accuracy: 0.3091 - val_loss: 2.6188 - val_categorical_accuracy: 0.3363\n",
      "Epoch 6/100\n",
      "1590/1590 [==============================] - 78s 49ms/step - loss: 2.2042 - categorical_accuracy: 0.3221 - val_loss: 2.3773 - val_categorical_accuracy: 0.3504\n",
      "Epoch 7/100\n",
      "1590/1590 [==============================] - 79s 50ms/step - loss: 2.1709 - categorical_accuracy: 0.3300 - val_loss: 2.5039 - val_categorical_accuracy: 0.3584\n",
      "Epoch 8/100\n",
      "1590/1590 [==============================] - 80s 50ms/step - loss: 2.1054 - categorical_accuracy: 0.3529 - val_loss: 2.4584 - val_categorical_accuracy: 0.3614\n",
      "Epoch 9/100\n",
      "1590/1590 [==============================] - 79s 50ms/step - loss: 2.0983 - categorical_accuracy: 0.3524 - val_loss: 2.4476 - val_categorical_accuracy: 0.3739\n",
      "Epoch 10/100\n",
      "1590/1590 [==============================] - 80s 50ms/step - loss: 2.0607 - categorical_accuracy: 0.3705 - val_loss: 2.5004 - val_categorical_accuracy: 0.3639\n",
      "Epoch 11/100\n",
      "1590/1590 [==============================] - 82s 51ms/step - loss: 2.0284 - categorical_accuracy: 0.3649 - val_loss: 2.4582 - val_categorical_accuracy: 0.3639\n",
      "Epoch 12/100\n",
      "1590/1590 [==============================] - 78s 49ms/step - loss: 2.0119 - categorical_accuracy: 0.3732 - val_loss: 2.4618 - val_categorical_accuracy: 0.3699\n",
      "Epoch 13/100\n",
      "1590/1590 [==============================] - 77s 48ms/step - loss: 1.9720 - categorical_accuracy: 0.3871 - val_loss: 2.2956 - val_categorical_accuracy: 0.3840\n",
      "Epoch 14/100\n",
      "1590/1590 [==============================] - 77s 48ms/step - loss: 1.9344 - categorical_accuracy: 0.4010 - val_loss: 2.5092 - val_categorical_accuracy: 0.3674\n",
      "Epoch 15/100\n",
      "1590/1590 [==============================] - 76s 48ms/step - loss: 1.9171 - categorical_accuracy: 0.4017 - val_loss: 2.4125 - val_categorical_accuracy: 0.3880\n",
      "Epoch 16/100\n",
      "1590/1590 [==============================] - 77s 48ms/step - loss: 1.8962 - categorical_accuracy: 0.4079 - val_loss: 2.3890 - val_categorical_accuracy: 0.3734\n",
      "Epoch 17/100\n",
      "1590/1590 [==============================] - 79s 50ms/step - loss: 1.8693 - categorical_accuracy: 0.4194 - val_loss: 2.4868 - val_categorical_accuracy: 0.3759\n",
      "Epoch 18/100\n",
      "1590/1590 [==============================] - 80s 50ms/step - loss: 1.8455 - categorical_accuracy: 0.4250 - val_loss: 2.4912 - val_categorical_accuracy: 0.3619\n",
      "Epoch 19/100\n",
      "1590/1590 [==============================] - 80s 50ms/step - loss: 1.8398 - categorical_accuracy: 0.4185 - val_loss: 2.5165 - val_categorical_accuracy: 0.3855\n",
      "Epoch 20/100\n",
      "1590/1590 [==============================] - 79s 50ms/step - loss: 1.7953 - categorical_accuracy: 0.4367 - val_loss: 2.5417 - val_categorical_accuracy: 0.3664\n",
      "Epoch 21/100\n",
      "1590/1590 [==============================] - 80s 50ms/step - loss: 1.8054 - categorical_accuracy: 0.4350 - val_loss: 2.4496 - val_categorical_accuracy: 0.3905\n",
      "Epoch 22/100\n",
      "1590/1590 [==============================] - 81s 51ms/step - loss: 1.7837 - categorical_accuracy: 0.4392 - val_loss: 2.6362 - val_categorical_accuracy: 0.3699\n",
      "Epoch 23/100\n",
      "1590/1590 [==============================] - 81s 51ms/step - loss: 1.7570 - categorical_accuracy: 0.4566 - val_loss: 2.6665 - val_categorical_accuracy: 0.3749\n",
      "Epoch 24/100\n",
      "1590/1590 [==============================] - 80s 50ms/step - loss: 1.7588 - categorical_accuracy: 0.4487 - val_loss: 2.6757 - val_categorical_accuracy: 0.3739\n",
      "Epoch 25/100\n",
      "1590/1590 [==============================] - 80s 50ms/step - loss: 1.7082 - categorical_accuracy: 0.4650 - val_loss: 2.6767 - val_categorical_accuracy: 0.3724\n",
      "Epoch 26/100\n",
      "1590/1590 [==============================] - 79s 49ms/step - loss: 1.6984 - categorical_accuracy: 0.4618 - val_loss: 2.8955 - val_categorical_accuracy: 0.3539\n",
      "Epoch 27/100\n",
      "1590/1590 [==============================] - 76s 48ms/step - loss: 1.6810 - categorical_accuracy: 0.4722 - val_loss: 2.9794 - val_categorical_accuracy: 0.3529\n",
      "Epoch 28/100\n",
      "1590/1590 [==============================] - 76s 48ms/step - loss: 1.6645 - categorical_accuracy: 0.4805 - val_loss: 2.7525 - val_categorical_accuracy: 0.3714\n",
      "Epoch 29/100\n",
      "1590/1590 [==============================] - 76s 48ms/step - loss: 1.6698 - categorical_accuracy: 0.4763 - val_loss: 2.7608 - val_categorical_accuracy: 0.3699\n",
      "Epoch 30/100\n",
      "1590/1590 [==============================] - 77s 48ms/step - loss: 1.6396 - categorical_accuracy: 0.4857 - val_loss: 2.8155 - val_categorical_accuracy: 0.3739\n",
      "Epoch 31/100\n",
      "1590/1590 [==============================] - 77s 48ms/step - loss: 1.6177 - categorical_accuracy: 0.4948 - val_loss: 2.8405 - val_categorical_accuracy: 0.3659\n",
      "Epoch 32/100\n",
      "1590/1590 [==============================] - 77s 48ms/step - loss: 1.6035 - categorical_accuracy: 0.4940 - val_loss: 2.8940 - val_categorical_accuracy: 0.3634\n",
      "Epoch 33/100\n",
      "1590/1590 [==============================] - 78s 49ms/step - loss: 1.6059 - categorical_accuracy: 0.4951 - val_loss: 2.9646 - val_categorical_accuracy: 0.3724\n",
      "Epoch 34/100\n",
      "1590/1590 [==============================] - 77s 48ms/step - loss: 1.5706 - categorical_accuracy: 0.5042 - val_loss: 2.9699 - val_categorical_accuracy: 0.3539\n",
      "Epoch 35/100\n",
      "1590/1590 [==============================] - 77s 49ms/step - loss: 1.5580 - categorical_accuracy: 0.5057 - val_loss: 2.9077 - val_categorical_accuracy: 0.3554\n",
      "Epoch 36/100\n",
      "1590/1590 [==============================] - 76s 48ms/step - loss: 1.5583 - categorical_accuracy: 0.5206 - val_loss: 3.1969 - val_categorical_accuracy: 0.3604\n",
      "Epoch 37/100\n",
      "1590/1590 [==============================] - 82s 52ms/step - loss: 1.5187 - categorical_accuracy: 0.5220 - val_loss: 3.0363 - val_categorical_accuracy: 0.3609\n",
      "Epoch 38/100\n",
      "1590/1590 [==============================] - 82s 51ms/step - loss: 1.5199 - categorical_accuracy: 0.5181 - val_loss: 3.0849 - val_categorical_accuracy: 0.3569\n",
      "Epoch 39/100\n",
      " 665/1590 [===========>..................] - ETA: 42s - loss: 1.5113 - categorical_accuracy: 0.5299"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d4/2tkf12c121j9pm73mz8hvsd40000gn/T/ipykernel_62811/1905934004.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 다시 한 번 모델을 학습시킵니다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# (이번엔 상위 2개의 inception 블록을 상위의 밀집 레이어들과 함께 파인튜닝합니다)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m history = model.fit_generator(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1590\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0;34m'Please use `Model.fit`, which supports generators.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m         stacklevel=2)\n\u001b[0;32m-> 2016\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   2017\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.adam_v2.Adam(learning_rate=0.0001), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "# 다시 한 번 모델을 학습시킵니다\n",
    "# (이번엔 상위 2개의 inception 블록을 상위의 밀집 레이어들과 함께 파인튜닝합니다)\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 1590, \n",
    "    epochs=100,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps= 399, \n",
    "    #verbose=2,\n",
    "    #callbacks=callbacks_list \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inception_V3 모델로도 35% 이상의 검증 정확도 달성하지 못했다. \n",
    "# 원인이 뭐지? <- 연구. 공부가 필요하다. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35eb7306ee2d642baa30dd47b3f48e3de4de9582bbd530539ad6f76f0b00bf2b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf25')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
