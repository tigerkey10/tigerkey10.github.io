{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 광고영상 프레임들 훈련용 / 검증용 셋으로 편입 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import shutil \n",
    "\n",
    "sys.path.append('/Users/kibeomkim/Desktop/영상프레임/')\n",
    "\n",
    "video_list = os.listdir('/Users/kibeomkim/Desktop/영상프레임')\n",
    "video_list.remove('.DS_Store')\n",
    "# 훈련용 비디오 리스트 \n",
    "train_video_list = video_list[:25]\n",
    "# 테스트용 비디오 리스트 \n",
    "test_video_list = video_list[25:]\n",
    "\n",
    "for video in train_video_list : \n",
    "    for frame in os.listdir(f'/Users/kibeomkim/Desktop/영상프레임/{video}') : # 훈련용 비디오 프레임 하나하나에 대해서 \n",
    "        shutil.copyfile(f'/Users/kibeomkim/Desktop/영상프레임/{video}/{frame}', f'/Users/kibeomkim/Desktop/openlogo_video/train/samsung/{frame}')\n",
    "\n",
    "for video in test_video_list : \n",
    "    for frame in os.listdir(f'/Users/kibeomkim/Desktop/영상프레임/{video}') : # 테스트 비디오 프레임 하나하나에 대해서 \n",
    "        shutil.copyfile(f'/Users/kibeomkim/Desktop/영상프레임/{video}/{frame}', f'/Users/kibeomkim/Desktop/openlogo_video/test/samsung/{frame}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception 모델에 갤럭시 S21 광고 영상 프레임들 넣기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 150, 150, 3)      12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " xception (Functional)       (None, 5, 5, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_6   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,865,590\n",
      "Trainable params: 4,104\n",
      "Non-trainable params: 20,861,486\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras.applications import xception\n",
    "from keras import layers\n",
    "from keras import preprocessing\n",
    "\n",
    "base_model = keras.applications.xception.Xception(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "\n",
    "norm_layer = keras.layers.BatchNormalization()\n",
    "x = norm_layer(inputs)\n",
    "\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.5)(x)  # Regularize with dropout\n",
    "outputs = keras.layers.Dense(2)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40783 images belonging to 2 classes.\n",
      "Found 17106 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 이미지 데이터 전처리 # 데이터 증식 사용\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.6,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # 검증데이터는 증식하지 않는다.\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/kibeomkim/Desktop/openlogo_video/train', \n",
    "    target_size=(150, 150),\n",
    "    batch_size=100, \n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    '/Users/kibeomkim/Desktop/openlogo_video/test',\n",
    "    target_size=(150,150),\n",
    "    batch_size=100,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 기본적인 3가지 콜백 \n",
    "callbacks_list = [\n",
    "\n",
    "    #과대적합 발생 시 조기 스톱 콜백\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='binary_accuracy', # 모델 검증 손실 모니터링\n",
    "        patience= 10), # 20에폭동안 과대적합 관찰\n",
    "    \n",
    "    # 최고의 가중치 자동 저장 콜백\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        '/Users/kibeomkim/Desktop/models_saved/my_model.h5', \n",
    "        monitor = 'val_loss', \n",
    "        save_best_only = True), \n",
    "\n",
    "    # 학습률 자동 조정 콜백\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=5\n",
    "    ),\n",
    "\n",
    "    # 텐서보드 \n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir = '/Users/kibeomkim/Desktop/my_log_dir',\n",
    "        histogram_freq = 1, # 1에포크마다 층 출력의 히스토그램 기록\n",
    "        embeddings_freq = 1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-24 09:41:27.454061: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/407 [==============================] - ETA: 0s - loss: 2.2502 - binary_accuracy: 0.7689"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-24 09:54:22.837151: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/407 [==============================] - 898s 2s/step - loss: 2.2502 - binary_accuracy: 0.7689 - val_loss: 1.2519 - val_binary_accuracy: 0.8592 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "407/407 [==============================] - 927s 2s/step - loss: 1.7378 - binary_accuracy: 0.8332 - val_loss: 1.5619 - val_binary_accuracy: 0.8357 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "407/407 [==============================] - 904s 2s/step - loss: 1.7898 - binary_accuracy: 0.8398 - val_loss: 1.4706 - val_binary_accuracy: 0.8470 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "407/407 [==============================] - 876s 2s/step - loss: 1.6287 - binary_accuracy: 0.8539 - val_loss: 1.7315 - val_binary_accuracy: 0.8270 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "407/407 [==============================] - 902s 2s/step - loss: 1.8477 - binary_accuracy: 0.8441 - val_loss: 1.5527 - val_binary_accuracy: 0.8496 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "import keras.optimizers\n",
    "\n",
    "# 모델 컴파일 \n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.adam_v2.Adam(), \n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['binary_accuracy']\n",
    ")\n",
    "\n",
    "# 모델 훈련 \n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 407, \n",
    "    epochs=5,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps=171, \n",
    "    callbacks=callbacks_list \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/Users/kibeomkim/Desktop/models_saved/video_trained_model.h5') # 모델 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 150, 150, 3)      12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " xception (Functional)       (None, 5, 5, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_6   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,865,590\n",
      "Trainable params: 20,811,056\n",
      "Non-trainable params: 54,534\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-24 10:57:01.517156: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/407 [==============================] - ETA: 0s - loss: 1.0450 - binary_accuracy: 0.9047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-24 11:31:48.445260: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/407 [==============================] - 2218s 5s/step - loss: 1.0450 - binary_accuracy: 0.9047 - val_loss: 1.1603 - val_binary_accuracy: 0.8716 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# 미세조정 \n",
    "base_model.trainable = True\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.adam_v2.Adam(learning_rate=1e-5), \n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['binary_accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 407, \n",
    "    epochs=1,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps=171, \n",
    "    callbacks=callbacks_list \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/Users/kibeomkim/Desktop/models_saved/fine_tuned_video_trained_model.h5') # 모델 저장 "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c69af78ec1296bb8dce567f7dc582a831aacc25113635b0c93ed6d0ebdf014b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
