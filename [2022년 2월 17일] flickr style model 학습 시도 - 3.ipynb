{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1차, 2차 학습 시도 실패했다.\n",
    "# 모델 자체가 한계 있는 건 아닐까? \n",
    "# 모델을 바꿔보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 15:38:35.970758: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-17 15:38:35.971001: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " xception (Functional)       (None, 5, 5, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                40980     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,902,460\n",
      "Trainable params: 40,980\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras.applications import xception\n",
    "from keras import layers\n",
    "from keras import preprocessing\n",
    "\n",
    "base_model = keras.applications.xception.Xception(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "\n",
    "norm_layer = keras.layers.BatchNormalization()\n",
    "x = norm_layer(inputs)\n",
    "\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.5)(x)  # Regularize with dropout\n",
    "outputs = keras.layers.Dense(20)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7993 images belonging to 20 classes.\n",
      "Found 1999 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "# 이미지 데이터 전처리 # 데이터 증식 사용\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # 검증데이터는 증식하지 않는다.\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/kibeomkim/Desktop/flickr/train', \n",
    "    target_size=(150, 150),\n",
    "    batch_size=100, \n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    '/Users/kibeomkim/Desktop/flickr/test',\n",
    "    target_size=(150,150),\n",
    "    batch_size=50,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 기본적인 3가지 콜백 \n",
    "callbacks_list = [\n",
    "\n",
    "    #과대적합 발생 시 조기 스톱 콜백\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_categorical_accuracy', # 모델 검증 손실 모니터링\n",
    "        patience= 20), # 20에폭동안 과대적합 관찰\n",
    "    \n",
    "    # 최고의 가중치 자동 저장 콜백\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        '/Users/kibeomkim/Desktop/models_saved/my_model.h5', \n",
    "        monitor = 'val_loss', \n",
    "        save_best_only = True), \n",
    "\n",
    "    # 학습률 자동 조정 콜백\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=5\n",
    "    ),\n",
    "\n",
    "    # 텐서보드 \n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir = '/Users/kibeomkim/Desktop/my_log_dir',\n",
    "        histogram_freq = 1, # 1에포크마다 층 출력의 히스토그램 기록\n",
    "        embeddings_freq = 1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 12:26:10.365633: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-17 12:28:43.899119: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 - 171s - loss: 2.5442 - categorical_accuracy: 0.2317 - val_loss: 2.2189 - val_categorical_accuracy: 0.3397 - lr: 0.0010 - 171s/epoch - 2s/step\n",
      "Epoch 2/15\n",
      "80/80 - 174s - loss: 2.1429 - categorical_accuracy: 0.3451 - val_loss: 2.1385 - val_categorical_accuracy: 0.3557 - lr: 0.0010 - 174s/epoch - 2s/step\n",
      "Epoch 3/15\n",
      "80/80 - 169s - loss: 2.0243 - categorical_accuracy: 0.3771 - val_loss: 2.1109 - val_categorical_accuracy: 0.3552 - lr: 0.0010 - 169s/epoch - 2s/step\n",
      "Epoch 4/15\n",
      "80/80 - 172s - loss: 1.9434 - categorical_accuracy: 0.3982 - val_loss: 2.0895 - val_categorical_accuracy: 0.3627 - lr: 0.0010 - 172s/epoch - 2s/step\n",
      "Epoch 5/15\n",
      "80/80 - 158s - loss: 1.8921 - categorical_accuracy: 0.4111 - val_loss: 2.0716 - val_categorical_accuracy: 0.3767 - lr: 0.0010 - 158s/epoch - 2s/step\n",
      "Epoch 6/15\n",
      "80/80 - 161s - loss: 1.8436 - categorical_accuracy: 0.4269 - val_loss: 2.0791 - val_categorical_accuracy: 0.3732 - lr: 0.0010 - 161s/epoch - 2s/step\n",
      "Epoch 7/15\n",
      "80/80 - 162s - loss: 1.8159 - categorical_accuracy: 0.4336 - val_loss: 2.0787 - val_categorical_accuracy: 0.3727 - lr: 0.0010 - 162s/epoch - 2s/step\n",
      "Epoch 8/15\n",
      "80/80 - 159s - loss: 1.7966 - categorical_accuracy: 0.4410 - val_loss: 2.0941 - val_categorical_accuracy: 0.3767 - lr: 0.0010 - 159s/epoch - 2s/step\n",
      "Epoch 9/15\n",
      "80/80 - 158s - loss: 1.7503 - categorical_accuracy: 0.4588 - val_loss: 2.0936 - val_categorical_accuracy: 0.3707 - lr: 0.0010 - 158s/epoch - 2s/step\n",
      "Epoch 10/15\n",
      "80/80 - 160s - loss: 1.7309 - categorical_accuracy: 0.4594 - val_loss: 2.0702 - val_categorical_accuracy: 0.3772 - lr: 0.0010 - 160s/epoch - 2s/step\n",
      "Epoch 11/15\n",
      "80/80 - 164s - loss: 1.7088 - categorical_accuracy: 0.4647 - val_loss: 2.0890 - val_categorical_accuracy: 0.3717 - lr: 0.0010 - 164s/epoch - 2s/step\n",
      "Epoch 12/15\n",
      "80/80 - 158s - loss: 1.6968 - categorical_accuracy: 0.4680 - val_loss: 2.0773 - val_categorical_accuracy: 0.3792 - lr: 0.0010 - 158s/epoch - 2s/step\n",
      "Epoch 13/15\n",
      "80/80 - 160s - loss: 1.6659 - categorical_accuracy: 0.4773 - val_loss: 2.0886 - val_categorical_accuracy: 0.3667 - lr: 0.0010 - 160s/epoch - 2s/step\n",
      "Epoch 14/15\n",
      "80/80 - 159s - loss: 1.6554 - categorical_accuracy: 0.4824 - val_loss: 2.0904 - val_categorical_accuracy: 0.3657 - lr: 0.0010 - 159s/epoch - 2s/step\n",
      "Epoch 15/15\n",
      "80/80 - 161s - loss: 1.6388 - categorical_accuracy: 0.4894 - val_loss: 2.0946 - val_categorical_accuracy: 0.3717 - lr: 0.0010 - 161s/epoch - 2s/step\n"
     ]
    }
   ],
   "source": [
    "import keras.optimizers\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.adam_v2.Adam(), \n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics = [keras.metrics.CategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 80, \n",
    "    epochs=15,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps=40, \n",
    "    verbose=2,\n",
    "    callbacks=callbacks_list \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 미세조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_46 (InputLayer)       [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " batch_normalization_97 (Bat  (None, 150, 150, 3)      12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " xception (Functional)       (None, 5, 5, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_14  (None, 2048)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 20)                40980     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,902,472\n",
      "Trainable params: 20,847,938\n",
      "Non-trainable params: 54,534\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 13:07:33.502734: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-17 13:12:58.425582: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 - 344s - loss: 1.5614 - categorical_accuracy: 0.5147 - val_loss: 2.0397 - val_categorical_accuracy: 0.3912 - lr: 1.0000e-05 - 344s/epoch - 4s/step\n",
      "Epoch 2/200\n",
      "80/80 - 408s - loss: 1.4674 - categorical_accuracy: 0.5316 - val_loss: 2.0342 - val_categorical_accuracy: 0.4007 - lr: 1.0000e-05 - 408s/epoch - 5s/step\n",
      "Epoch 3/200\n",
      "80/80 - 399s - loss: 1.4188 - categorical_accuracy: 0.5485 - val_loss: 2.0229 - val_categorical_accuracy: 0.3997 - lr: 1.0000e-05 - 399s/epoch - 5s/step\n",
      "Epoch 4/200\n",
      "80/80 - 403s - loss: 1.3628 - categorical_accuracy: 0.5662 - val_loss: 2.0290 - val_categorical_accuracy: 0.4022 - lr: 1.0000e-05 - 403s/epoch - 5s/step\n",
      "Epoch 5/200\n",
      "80/80 - 327s - loss: 1.3190 - categorical_accuracy: 0.5826 - val_loss: 2.0430 - val_categorical_accuracy: 0.4037 - lr: 1.0000e-05 - 327s/epoch - 4s/step\n",
      "Epoch 6/200\n",
      "80/80 - 327s - loss: 1.2699 - categorical_accuracy: 0.5945 - val_loss: 2.0494 - val_categorical_accuracy: 0.4072 - lr: 1.0000e-05 - 327s/epoch - 4s/step\n",
      "Epoch 7/200\n",
      "80/80 - 329s - loss: 1.2392 - categorical_accuracy: 0.6008 - val_loss: 2.0494 - val_categorical_accuracy: 0.4087 - lr: 1.0000e-05 - 329s/epoch - 4s/step\n",
      "Epoch 8/200\n",
      "80/80 - 352s - loss: 1.1892 - categorical_accuracy: 0.6195 - val_loss: 2.0524 - val_categorical_accuracy: 0.4082 - lr: 1.0000e-05 - 352s/epoch - 4s/step\n",
      "Epoch 9/200\n",
      "80/80 - 341s - loss: 1.1407 - categorical_accuracy: 0.6321 - val_loss: 2.0677 - val_categorical_accuracy: 0.4092 - lr: 1.0000e-05 - 341s/epoch - 4s/step\n",
      "Epoch 10/200\n",
      "80/80 - 300s - loss: 1.1002 - categorical_accuracy: 0.6494 - val_loss: 2.0980 - val_categorical_accuracy: 0.4057 - lr: 1.0000e-05 - 300s/epoch - 4s/step\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d4/2tkf12c121j9pm73mz8hvsd40000gn/T/ipykernel_21247/1850580284.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m history = model.fit_generator(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0;34m'Please use `Model.fit`, which supports generators.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m         stacklevel=2)\n\u001b[0;32m-> 2016\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   2017\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1209\u001b[0m             with tf.profiler.experimental.Trace(\n\u001b[1;32m   1210\u001b[0m                 \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1248\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m       \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m       can_run_full_execution = (\n\u001b[1;32m   1252\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    643\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    647\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.adam_v2.Adam(1e-5),  # Low learning rate\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 80, \n",
    "    epochs=200,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps=40, \n",
    "    verbose=2,\n",
    "    callbacks=callbacks_list \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception 모델도 40% 이상 검증 성능 향상되지 않았다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 소규모 컨브넷 만들어보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers \n",
    "from keras import models \n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3),activation='relu', input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128, (3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128, (3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 17, 17, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               3211776   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20)                10260     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,462,868\n",
      "Trainable params: 3,462,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizers.adam_v2.Adam(learning_rate=0.001),\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 14:39:04.097210: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-02-17 14:39:04.255970: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 14:39:42.778494: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 44s - loss: 2.7822 - acc: 0.1468 - val_loss: 2.7695 - val_acc: 0.1526 - lr: 0.0010 - 44s/epoch - 545ms/step\n",
      "Epoch 2/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 42s - loss: 2.5629 - acc: 0.2141 - val_loss: 2.5590 - val_acc: 0.2226 - lr: 0.0010 - 42s/epoch - 528ms/step\n",
      "Epoch 3/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 42s - loss: 2.4609 - acc: 0.2427 - val_loss: 2.4528 - val_acc: 0.2376 - lr: 0.0010 - 42s/epoch - 531ms/step\n",
      "Epoch 4/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 42s - loss: 2.3812 - acc: 0.2669 - val_loss: 2.4346 - val_acc: 0.2441 - lr: 0.0010 - 42s/epoch - 526ms/step\n",
      "Epoch 5/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 42s - loss: 2.3176 - acc: 0.2852 - val_loss: 2.4010 - val_acc: 0.2526 - lr: 0.0010 - 42s/epoch - 529ms/step\n",
      "Epoch 6/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 46s - loss: 2.2855 - acc: 0.2966 - val_loss: 2.4305 - val_acc: 0.2611 - lr: 0.0010 - 46s/epoch - 575ms/step\n",
      "Epoch 7/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 43s - loss: 2.2281 - acc: 0.3085 - val_loss: 2.3754 - val_acc: 0.2706 - lr: 0.0010 - 43s/epoch - 540ms/step\n",
      "Epoch 8/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 46s - loss: 2.1792 - acc: 0.3288 - val_loss: 2.3344 - val_acc: 0.2801 - lr: 0.0010 - 46s/epoch - 574ms/step\n",
      "Epoch 9/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 42s - loss: 2.1337 - acc: 0.3355 - val_loss: 2.3487 - val_acc: 0.2791 - lr: 0.0010 - 42s/epoch - 530ms/step\n",
      "Epoch 10/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 42s - loss: 2.1199 - acc: 0.3462 - val_loss: 2.3451 - val_acc: 0.2891 - lr: 0.0010 - 42s/epoch - 527ms/step\n",
      "Epoch 11/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 44s - loss: 2.0614 - acc: 0.3617 - val_loss: 2.4028 - val_acc: 0.2821 - lr: 0.0010 - 44s/epoch - 547ms/step\n",
      "Epoch 12/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 43s - loss: 2.0245 - acc: 0.3708 - val_loss: 2.3161 - val_acc: 0.2931 - lr: 0.0010 - 43s/epoch - 539ms/step\n",
      "Epoch 13/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 43s - loss: 1.9851 - acc: 0.3813 - val_loss: 2.4267 - val_acc: 0.2871 - lr: 0.0010 - 43s/epoch - 537ms/step\n",
      "Epoch 14/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 45s - loss: 1.9462 - acc: 0.3835 - val_loss: 2.3736 - val_acc: 0.2821 - lr: 0.0010 - 45s/epoch - 567ms/step\n",
      "Epoch 15/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 45s - loss: 1.8946 - acc: 0.4011 - val_loss: 2.3854 - val_acc: 0.2971 - lr: 0.0010 - 45s/epoch - 557ms/step\n",
      "Epoch 16/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 42s - loss: 1.8787 - acc: 0.4042 - val_loss: 2.4779 - val_acc: 0.2726 - lr: 0.0010 - 42s/epoch - 526ms/step\n",
      "Epoch 17/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 46s - loss: 1.8107 - acc: 0.4308 - val_loss: 2.5073 - val_acc: 0.2781 - lr: 0.0010 - 46s/epoch - 581ms/step\n",
      "Epoch 18/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 46s - loss: 1.7726 - acc: 0.4455 - val_loss: 2.5557 - val_acc: 0.2681 - lr: 0.0010 - 46s/epoch - 580ms/step\n",
      "Epoch 19/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 49s - loss: 1.7166 - acc: 0.4579 - val_loss: 2.4412 - val_acc: 0.2866 - lr: 0.0010 - 49s/epoch - 606ms/step\n",
      "Epoch 20/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 43s - loss: 1.6860 - acc: 0.4637 - val_loss: 2.5167 - val_acc: 0.2921 - lr: 0.0010 - 43s/epoch - 543ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28a6dff40>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=80,\n",
    "    epochs=20,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps=40,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception 모델로 재시도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 150, 150, 3)      12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " xception (Functional)       (None, 5, 5, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_6   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 20)                40980     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,902,472\n",
      "Trainable params: 40,986\n",
      "Non-trainable params: 20,861,486\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras.applications import xception\n",
    "from keras import layers\n",
    "from keras import preprocessing\n",
    "\n",
    "base_model = keras.applications.xception.Xception(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "\n",
    "norm_layer = keras.layers.BatchNormalization()\n",
    "x = norm_layer(inputs)\n",
    "\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.7)(x)  # Regularize with dropout\n",
    "outputs = keras.layers.Dense(20)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7993 images belonging to 20 classes.\n",
      "Found 1999 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "# 이미지 데이터 전처리 # 데이터 증식 사용\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.5,\n",
    "    zoom_range=[0.8, 2.0],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip = True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # 검증데이터는 증식하지 않는다.\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/kibeomkim/Desktop/flickr/train', \n",
    "    target_size=(150, 150),\n",
    "    batch_size=5, \n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    '/Users/kibeomkim/Desktop/flickr/test',\n",
    "    target_size=(150,150),\n",
    "    batch_size=5,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 기본적인 3가지 콜백 \n",
    "callbacks_list = [\n",
    "\n",
    "    #과대적합 발생 시 조기 스톱 콜백\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_categorical_accuracy', # 모델 검증 손실 모니터링\n",
    "        patience= 20), # 20에폭동안 과대적합 관찰\n",
    "    \n",
    "    # 최고의 가중치 자동 저장 콜백\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        '/Users/kibeomkim/Desktop/models_saved/my_model.h5', \n",
    "        monitor = 'val_loss', \n",
    "        save_best_only = True), \n",
    "\n",
    "    # 학습률 자동 조정 콜백\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=10\n",
    "    ),\n",
    "\n",
    "    # 텐서보드 \n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir = '/Users/kibeomkim/Desktop/my_log_dir',\n",
    "        histogram_freq = 1, # 1에포크마다 층 출력의 히스토그램 기록\n",
    "        embeddings_freq = 1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 16:41:19.884921: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-17 16:42:54.754333: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 - 109s - loss: 3.0020 - categorical_accuracy: 0.1800 - val_loss: 2.4486 - val_categorical_accuracy: 0.2680 - lr: 0.0010 - 109s/epoch - 109ms/step\n",
      "Epoch 2/15\n",
      "1000/1000 - 110s - loss: 2.8055 - categorical_accuracy: 0.2274 - val_loss: 2.4083 - val_categorical_accuracy: 0.3020 - lr: 0.0010 - 110s/epoch - 110ms/step\n",
      "Epoch 3/15\n",
      "1000/1000 - 139s - loss: 2.7206 - categorical_accuracy: 0.2570 - val_loss: 2.4967 - val_categorical_accuracy: 0.2633 - lr: 0.0010 - 139s/epoch - 139ms/step\n",
      "Epoch 4/15\n",
      "1000/1000 - 120s - loss: 2.7093 - categorical_accuracy: 0.2614 - val_loss: 2.4827 - val_categorical_accuracy: 0.2973 - lr: 0.0010 - 120s/epoch - 120ms/step\n",
      "Epoch 5/15\n",
      "1000/1000 - 111s - loss: 2.6852 - categorical_accuracy: 0.2709 - val_loss: 2.4216 - val_categorical_accuracy: 0.3113 - lr: 0.0010 - 111s/epoch - 111ms/step\n",
      "Epoch 6/15\n",
      "1000/1000 - 105s - loss: 2.6497 - categorical_accuracy: 0.2729 - val_loss: 2.4531 - val_categorical_accuracy: 0.2987 - lr: 0.0010 - 105s/epoch - 105ms/step\n",
      "Epoch 7/15\n",
      "1000/1000 - 104s - loss: 2.6653 - categorical_accuracy: 0.2753 - val_loss: 2.5442 - val_categorical_accuracy: 0.2660 - lr: 0.0010 - 104s/epoch - 104ms/step\n",
      "Epoch 8/15\n",
      "1000/1000 - 107s - loss: 2.6353 - categorical_accuracy: 0.2834 - val_loss: 2.5151 - val_categorical_accuracy: 0.3160 - lr: 0.0010 - 107s/epoch - 107ms/step\n",
      "Epoch 9/15\n",
      "1000/1000 - 108s - loss: 2.6293 - categorical_accuracy: 0.2866 - val_loss: 2.5144 - val_categorical_accuracy: 0.2987 - lr: 0.0010 - 108s/epoch - 108ms/step\n",
      "Epoch 10/15\n",
      "1000/1000 - 106s - loss: 2.6343 - categorical_accuracy: 0.2829 - val_loss: 2.4416 - val_categorical_accuracy: 0.3113 - lr: 0.0010 - 106s/epoch - 106ms/step\n",
      "Epoch 11/15\n",
      "1000/1000 - 107s - loss: 2.5710 - categorical_accuracy: 0.2877 - val_loss: 2.3752 - val_categorical_accuracy: 0.3313 - lr: 0.0010 - 107s/epoch - 107ms/step\n",
      "Epoch 12/15\n",
      "1000/1000 - 106s - loss: 2.5859 - categorical_accuracy: 0.2948 - val_loss: 2.4472 - val_categorical_accuracy: 0.3007 - lr: 0.0010 - 106s/epoch - 106ms/step\n",
      "Epoch 13/15\n",
      "1000/1000 - 106s - loss: 2.5859 - categorical_accuracy: 0.2985 - val_loss: 2.4963 - val_categorical_accuracy: 0.2860 - lr: 0.0010 - 106s/epoch - 106ms/step\n",
      "Epoch 14/15\n",
      "1000/1000 - 107s - loss: 2.5435 - categorical_accuracy: 0.2982 - val_loss: 2.4627 - val_categorical_accuracy: 0.3033 - lr: 0.0010 - 107s/epoch - 107ms/step\n",
      "Epoch 15/15\n",
      "1000/1000 - 108s - loss: 2.5538 - categorical_accuracy: 0.2985 - val_loss: 2.4954 - val_categorical_accuracy: 0.3253 - lr: 0.0010 - 108s/epoch - 108ms/step\n"
     ]
    }
   ],
   "source": [
    "import keras.optimizers\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.adam_v2.Adam(), \n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics = [keras.metrics.CategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 1590, \n",
    "    epochs=15,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps= 399, \n",
    "    #verbose=2,\n",
    "    callbacks=callbacks_list \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 미세조정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 17:09:12.021406: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1590/1590 [==============================] - ETA: 0s - loss: 2.1689 - categorical_accuracy: 0.3421"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 17:13:08.719141: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1590/1590 [==============================] - 257s 158ms/step - loss: 2.1689 - categorical_accuracy: 0.3421 - val_loss: 2.0722 - val_categorical_accuracy: 0.3729 - lr: 1.0000e-05\n",
      "Epoch 2/200\n",
      "1590/1590 [==============================] - 248s 156ms/step - loss: 1.9834 - categorical_accuracy: 0.3846 - val_loss: 1.9980 - val_categorical_accuracy: 0.3784 - lr: 1.0000e-05\n",
      "Epoch 3/200\n",
      "1590/1590 [==============================] - 253s 159ms/step - loss: 1.8674 - categorical_accuracy: 0.4207 - val_loss: 1.9540 - val_categorical_accuracy: 0.4040 - lr: 1.0000e-05\n",
      "Epoch 4/200\n",
      "1590/1590 [==============================] - 251s 158ms/step - loss: 1.8053 - categorical_accuracy: 0.4270 - val_loss: 1.9121 - val_categorical_accuracy: 0.4180 - lr: 1.0000e-05\n",
      "Epoch 5/200\n",
      "1590/1590 [==============================] - 249s 156ms/step - loss: 1.7413 - categorical_accuracy: 0.4497 - val_loss: 1.8884 - val_categorical_accuracy: 0.4115 - lr: 1.0000e-05\n",
      "Epoch 6/200\n",
      "1590/1590 [==============================] - 248s 156ms/step - loss: 1.6677 - categorical_accuracy: 0.4732 - val_loss: 1.8831 - val_categorical_accuracy: 0.4236 - lr: 1.0000e-05\n",
      "Epoch 7/200\n",
      "1590/1590 [==============================] - 246s 155ms/step - loss: 1.6004 - categorical_accuracy: 0.4903 - val_loss: 1.9044 - val_categorical_accuracy: 0.4201 - lr: 1.0000e-05\n",
      "Epoch 8/200\n",
      "1590/1590 [==============================] - 247s 156ms/step - loss: 1.5518 - categorical_accuracy: 0.5077 - val_loss: 1.8607 - val_categorical_accuracy: 0.4386 - lr: 1.0000e-05\n",
      "Epoch 9/200\n",
      "1590/1590 [==============================] - 248s 156ms/step - loss: 1.4911 - categorical_accuracy: 0.5283 - val_loss: 1.8885 - val_categorical_accuracy: 0.4301 - lr: 1.0000e-05\n",
      "Epoch 10/200\n",
      "1590/1590 [==============================] - 246s 155ms/step - loss: 1.4553 - categorical_accuracy: 0.5340 - val_loss: 1.8813 - val_categorical_accuracy: 0.4276 - lr: 1.0000e-05\n",
      "Epoch 11/200\n",
      "1590/1590 [==============================] - 245s 154ms/step - loss: 1.3858 - categorical_accuracy: 0.5566 - val_loss: 1.9058 - val_categorical_accuracy: 0.4371 - lr: 1.0000e-05\n",
      "Epoch 12/200\n",
      "1590/1590 [==============================] - 247s 155ms/step - loss: 1.3192 - categorical_accuracy: 0.5736 - val_loss: 1.9268 - val_categorical_accuracy: 0.4431 - lr: 1.0000e-05\n",
      "Epoch 13/200\n",
      "1590/1590 [==============================] - 245s 154ms/step - loss: 1.2777 - categorical_accuracy: 0.5872 - val_loss: 1.9240 - val_categorical_accuracy: 0.4326 - lr: 1.0000e-05\n",
      "Epoch 14/200\n",
      "1590/1590 [==============================] - 245s 154ms/step - loss: 1.2377 - categorical_accuracy: 0.6005 - val_loss: 1.9797 - val_categorical_accuracy: 0.4391 - lr: 1.0000e-05\n",
      "Epoch 15/200\n",
      "1590/1590 [==============================] - 246s 155ms/step - loss: 1.2039 - categorical_accuracy: 0.6100 - val_loss: 1.9630 - val_categorical_accuracy: 0.4296 - lr: 1.0000e-05\n",
      "Epoch 16/200\n",
      "1590/1590 [==============================] - 246s 154ms/step - loss: 1.1546 - categorical_accuracy: 0.6237 - val_loss: 1.9861 - val_categorical_accuracy: 0.4291 - lr: 1.0000e-05\n",
      "Epoch 17/200\n",
      "1590/1590 [==============================] - 247s 156ms/step - loss: 1.0956 - categorical_accuracy: 0.6379 - val_loss: 1.9870 - val_categorical_accuracy: 0.4326 - lr: 1.0000e-05\n",
      "Epoch 18/200\n",
      "1590/1590 [==============================] - 248s 156ms/step - loss: 1.0554 - categorical_accuracy: 0.6545 - val_loss: 2.0349 - val_categorical_accuracy: 0.4301 - lr: 1.0000e-05\n",
      "Epoch 19/200\n",
      "1590/1590 [==============================] - 249s 156ms/step - loss: 0.9551 - categorical_accuracy: 0.6831 - val_loss: 2.0580 - val_categorical_accuracy: 0.4381 - lr: 1.0000e-06\n",
      "Epoch 20/200\n",
      "1590/1590 [==============================] - 248s 156ms/step - loss: 0.9243 - categorical_accuracy: 0.7007 - val_loss: 2.0515 - val_categorical_accuracy: 0.4391 - lr: 1.0000e-06\n",
      "Epoch 21/200\n",
      "  85/1590 [>.............................] - ETA: 3:41 - loss: 0.8566 - categorical_accuracy: 0.7294"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d4/2tkf12c121j9pm73mz8hvsd40000gn/T/ipykernel_32017/1808842775.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m history = model.fit_generator(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1590\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0;34m'Please use `Model.fit`, which supports generators.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m         stacklevel=2)\n\u001b[0;32m-> 2016\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   2017\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "#model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.adam_v2.Adam(1e-5),  # Low learning rate\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 1590, \n",
    "    epochs=200,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps=399, \n",
    "    #verbose=2,\n",
    "    callbacks=callbacks_list \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7993 images belonging to 20 classes.\n",
      "Found 1999 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    rotation_range=120,\n",
    "    width_shift_range=0.8,\n",
    "    height_shift_range=0.8,\n",
    "    shear_range=0.8,\n",
    "    zoom_range=[0.1, 0.5],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip = True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # 검증데이터는 증식하지 않는다.\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/kibeomkim/Desktop/flickr/train', \n",
    "    target_size=(150, 150),\n",
    "    batch_size=5, \n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    '/Users/kibeomkim/Desktop/flickr/test',\n",
    "    target_size=(150,150),\n",
    "    batch_size=5,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 19:29:57.949264: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1590/1590 [==============================] - ETA: 0s - loss: 2.4793 - categorical_accuracy: 0.2329"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 19:33:53.680289: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1590/1590 [==============================] - 255s 158ms/step - loss: 2.4793 - categorical_accuracy: 0.2329 - val_loss: 1.8941 - val_categorical_accuracy: 0.4246 - lr: 1.0000e-06\n",
      "Epoch 2/200\n",
      "1590/1590 [==============================] - 249s 156ms/step - loss: 2.4680 - categorical_accuracy: 0.2378 - val_loss: 1.8880 - val_categorical_accuracy: 0.4306 - lr: 1.0000e-06\n",
      "Epoch 3/200\n",
      "1590/1590 [==============================] - 249s 156ms/step - loss: 2.4653 - categorical_accuracy: 0.2393 - val_loss: 1.8941 - val_categorical_accuracy: 0.4286 - lr: 1.0000e-06\n",
      "Epoch 4/200\n",
      "1590/1590 [==============================] - 243s 153ms/step - loss: 2.4647 - categorical_accuracy: 0.2389 - val_loss: 1.8948 - val_categorical_accuracy: 0.4326 - lr: 1.0000e-06\n",
      "Epoch 5/200\n",
      "1590/1590 [==============================] - 242s 152ms/step - loss: 2.4442 - categorical_accuracy: 0.2494 - val_loss: 1.8910 - val_categorical_accuracy: 0.4311 - lr: 1.0000e-06\n",
      "Epoch 6/200\n",
      "1590/1590 [==============================] - 242s 152ms/step - loss: 2.4523 - categorical_accuracy: 0.2398 - val_loss: 1.8963 - val_categorical_accuracy: 0.4281 - lr: 1.0000e-06\n",
      "Epoch 7/200\n",
      "1590/1590 [==============================] - 242s 152ms/step - loss: 2.4553 - categorical_accuracy: 0.2425 - val_loss: 1.8938 - val_categorical_accuracy: 0.4336 - lr: 1.0000e-06\n",
      "Epoch 8/200\n",
      "1590/1590 [==============================] - 242s 152ms/step - loss: 2.4358 - categorical_accuracy: 0.2484 - val_loss: 1.8941 - val_categorical_accuracy: 0.4326 - lr: 1.0000e-07\n",
      "Epoch 9/200\n",
      "1590/1590 [==============================] - 242s 152ms/step - loss: 2.4293 - categorical_accuracy: 0.2482 - val_loss: 1.8966 - val_categorical_accuracy: 0.4311 - lr: 1.0000e-07\n",
      "Epoch 10/200\n",
      "1590/1590 [==============================] - 242s 152ms/step - loss: 2.4304 - categorical_accuracy: 0.2508 - val_loss: 1.8960 - val_categorical_accuracy: 0.4321 - lr: 1.0000e-07\n",
      "Epoch 11/200\n",
      "1590/1590 [==============================] - 245s 154ms/step - loss: 2.4387 - categorical_accuracy: 0.2452 - val_loss: 1.8964 - val_categorical_accuracy: 0.4331 - lr: 1.0000e-07\n",
      "Epoch 12/200\n",
      "1590/1590 [==============================] - 243s 153ms/step - loss: 2.4522 - categorical_accuracy: 0.2423 - val_loss: 1.8961 - val_categorical_accuracy: 0.4331 - lr: 1.0000e-07\n",
      "Epoch 13/200\n",
      "1590/1590 [==============================] - 248s 156ms/step - loss: 2.4388 - categorical_accuracy: 0.2445 - val_loss: 1.8949 - val_categorical_accuracy: 0.4341 - lr: 1.0000e-08\n",
      "Epoch 14/200\n",
      "1590/1590 [==============================] - 249s 157ms/step - loss: 2.4374 - categorical_accuracy: 0.2472 - val_loss: 1.8913 - val_categorical_accuracy: 0.4346 - lr: 1.0000e-08\n",
      "Epoch 15/200\n",
      "1590/1590 [==============================] - 250s 157ms/step - loss: 2.4340 - categorical_accuracy: 0.2504 - val_loss: 1.8952 - val_categorical_accuracy: 0.4306 - lr: 1.0000e-08\n",
      "Epoch 16/200\n",
      "1590/1590 [==============================] - 250s 157ms/step - loss: 2.4381 - categorical_accuracy: 0.2518 - val_loss: 1.8968 - val_categorical_accuracy: 0.4336 - lr: 1.0000e-08\n",
      "Epoch 17/200\n",
      "1590/1590 [==============================] - 246s 155ms/step - loss: 2.4453 - categorical_accuracy: 0.2465 - val_loss: 1.8940 - val_categorical_accuracy: 0.4336 - lr: 1.0000e-08\n",
      "Epoch 18/200\n",
      "1590/1590 [==============================] - 245s 154ms/step - loss: 2.4437 - categorical_accuracy: 0.2524 - val_loss: 1.8938 - val_categorical_accuracy: 0.4326 - lr: 1.0000e-09\n",
      "Epoch 19/200\n",
      "1590/1590 [==============================] - 244s 154ms/step - loss: 2.4437 - categorical_accuracy: 0.2423 - val_loss: 1.8920 - val_categorical_accuracy: 0.4346 - lr: 1.0000e-09\n",
      "Epoch 20/200\n",
      "1590/1590 [==============================] - 247s 155ms/step - loss: 2.4385 - categorical_accuracy: 0.2475 - val_loss: 1.8971 - val_categorical_accuracy: 0.4326 - lr: 1.0000e-09\n",
      "Epoch 21/200\n",
      " 405/1590 [======>.......................] - ETA: 2:56 - loss: 2.4388 - categorical_accuracy: 0.2528"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d4/2tkf12c121j9pm73mz8hvsd40000gn/T/ipykernel_32017/2972310556.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m history = model.fit_generator(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1590\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0;34m'Please use `Model.fit`, which supports generators.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m         stacklevel=2)\n\u001b[0;32m-> 2016\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   2017\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.adam_v2.Adam(1e-6),  # Low learning rate\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 1590, \n",
    "    epochs=200,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps=399, \n",
    "    #verbose=2,\n",
    "    callbacks=callbacks_list \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시도: 과대적합 나타나기 시작할 때 학습 수동으로 끊고 데이터 증식 조건 바꿈. --> 새로운 조건 하에서 증식된 데이터를 모델이 새 데이터로 인지할 걸로 예상함. \n",
    "# 증식으로 클래스별 데이터 수를 늘리면 과대적합도 억제하고 일반화 성능도 끌어올릴 수 있겠다고 예상함. \n",
    "# 결과: 과대적합은 꽤 잘 억제한 듯 보이나, 일반화 성능 42~43% 대에서 더 이상 증가하지 않고 박스권에 갇힘. \n",
    "# 4차 시도 실패 "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35eb7306ee2d642baa30dd47b3f48e3de4de9582bbd530539ad6f76f0b00bf2b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf25')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
