{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1차, 2차 학습 시도 실패했다.\n",
    "# 모델 자체가 한계 있는 건 아닐까? \n",
    "# 모델을 바꿔보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_46 (InputLayer)       [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " batch_normalization_97 (Bat  (None, 150, 150, 3)      12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " xception (Functional)       (None, 5, 5, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_14  (None, 2048)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 20)                40980     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,902,472\n",
      "Trainable params: 40,986\n",
      "Non-trainable params: 20,861,486\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras.applications import xception\n",
    "from keras import layers\n",
    "from keras import preprocessing\n",
    "\n",
    "base_model = keras.applications.xception.Xception(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "\n",
    "norm_layer = keras.layers.BatchNormalization()\n",
    "x = norm_layer(inputs)\n",
    "\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "outputs = keras.layers.Dense(20)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7993 images belonging to 20 classes.\n",
      "Found 1999 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "# 이미지 데이터 전처리 # 데이터 증식 사용\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # 검증데이터는 증식하지 않는다.\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/kibeomkim/Desktop/flickr/train', \n",
    "    target_size=(150, 150),\n",
    "    batch_size=100, \n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    '/Users/kibeomkim/Desktop/flickr/test',\n",
    "    target_size=(150,150),\n",
    "    batch_size=50,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 기본적인 3가지 콜백 \n",
    "callbacks_list = [\n",
    "\n",
    "    #과대적합 발생 시 조기 스톱 콜백\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_categorical_accuracy', # 모델 검증 손실 모니터링\n",
    "        patience= 20), # 20에폭동안 과대적합 관찰\n",
    "    \n",
    "    # 최고의 가중치 자동 저장 콜백\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        '/Users/kibeomkim/Desktop/models_saved/my_model.h5', \n",
    "        monitor = 'val_loss', \n",
    "        save_best_only = True), \n",
    "\n",
    "    # 학습률 자동 조정 콜백\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=10\n",
    "    ),\n",
    "\n",
    "    # 텐서보드 \n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir = '/Users/kibeomkim/Desktop/my_log_dir',\n",
    "        histogram_freq = 1, # 1에포크마다 층 출력의 히스토그램 기록\n",
    "        embeddings_freq = 1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 12:26:10.365633: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-17 12:28:43.899119: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 - 171s - loss: 2.5442 - categorical_accuracy: 0.2317 - val_loss: 2.2189 - val_categorical_accuracy: 0.3397 - lr: 0.0010 - 171s/epoch - 2s/step\n",
      "Epoch 2/15\n",
      "80/80 - 174s - loss: 2.1429 - categorical_accuracy: 0.3451 - val_loss: 2.1385 - val_categorical_accuracy: 0.3557 - lr: 0.0010 - 174s/epoch - 2s/step\n",
      "Epoch 3/15\n",
      "80/80 - 169s - loss: 2.0243 - categorical_accuracy: 0.3771 - val_loss: 2.1109 - val_categorical_accuracy: 0.3552 - lr: 0.0010 - 169s/epoch - 2s/step\n",
      "Epoch 4/15\n",
      "80/80 - 172s - loss: 1.9434 - categorical_accuracy: 0.3982 - val_loss: 2.0895 - val_categorical_accuracy: 0.3627 - lr: 0.0010 - 172s/epoch - 2s/step\n",
      "Epoch 5/15\n",
      "80/80 - 158s - loss: 1.8921 - categorical_accuracy: 0.4111 - val_loss: 2.0716 - val_categorical_accuracy: 0.3767 - lr: 0.0010 - 158s/epoch - 2s/step\n",
      "Epoch 6/15\n",
      "80/80 - 161s - loss: 1.8436 - categorical_accuracy: 0.4269 - val_loss: 2.0791 - val_categorical_accuracy: 0.3732 - lr: 0.0010 - 161s/epoch - 2s/step\n",
      "Epoch 7/15\n",
      "80/80 - 162s - loss: 1.8159 - categorical_accuracy: 0.4336 - val_loss: 2.0787 - val_categorical_accuracy: 0.3727 - lr: 0.0010 - 162s/epoch - 2s/step\n",
      "Epoch 8/15\n",
      "80/80 - 159s - loss: 1.7966 - categorical_accuracy: 0.4410 - val_loss: 2.0941 - val_categorical_accuracy: 0.3767 - lr: 0.0010 - 159s/epoch - 2s/step\n",
      "Epoch 9/15\n",
      "80/80 - 158s - loss: 1.7503 - categorical_accuracy: 0.4588 - val_loss: 2.0936 - val_categorical_accuracy: 0.3707 - lr: 0.0010 - 158s/epoch - 2s/step\n",
      "Epoch 10/15\n",
      "80/80 - 160s - loss: 1.7309 - categorical_accuracy: 0.4594 - val_loss: 2.0702 - val_categorical_accuracy: 0.3772 - lr: 0.0010 - 160s/epoch - 2s/step\n",
      "Epoch 11/15\n",
      "80/80 - 164s - loss: 1.7088 - categorical_accuracy: 0.4647 - val_loss: 2.0890 - val_categorical_accuracy: 0.3717 - lr: 0.0010 - 164s/epoch - 2s/step\n",
      "Epoch 12/15\n",
      "80/80 - 158s - loss: 1.6968 - categorical_accuracy: 0.4680 - val_loss: 2.0773 - val_categorical_accuracy: 0.3792 - lr: 0.0010 - 158s/epoch - 2s/step\n",
      "Epoch 13/15\n",
      "80/80 - 160s - loss: 1.6659 - categorical_accuracy: 0.4773 - val_loss: 2.0886 - val_categorical_accuracy: 0.3667 - lr: 0.0010 - 160s/epoch - 2s/step\n",
      "Epoch 14/15\n",
      "80/80 - 159s - loss: 1.6554 - categorical_accuracy: 0.4824 - val_loss: 2.0904 - val_categorical_accuracy: 0.3657 - lr: 0.0010 - 159s/epoch - 2s/step\n",
      "Epoch 15/15\n",
      "80/80 - 161s - loss: 1.6388 - categorical_accuracy: 0.4894 - val_loss: 2.0946 - val_categorical_accuracy: 0.3717 - lr: 0.0010 - 161s/epoch - 2s/step\n"
     ]
    }
   ],
   "source": [
    "import keras.optimizers\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.adam_v2.Adam(), \n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics = [keras.metrics.CategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 80, \n",
    "    epochs=15,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps=40, \n",
    "    verbose=2,\n",
    "    callbacks=callbacks_list \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 미세조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_46 (InputLayer)       [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " batch_normalization_97 (Bat  (None, 150, 150, 3)      12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " xception (Functional)       (None, 5, 5, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_14  (None, 2048)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 20)                40980     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,902,472\n",
      "Trainable params: 20,847,938\n",
      "Non-trainable params: 54,534\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 13:07:33.502734: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-17 13:12:58.425582: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 - 344s - loss: 1.5614 - categorical_accuracy: 0.5147 - val_loss: 2.0397 - val_categorical_accuracy: 0.3912 - lr: 1.0000e-05 - 344s/epoch - 4s/step\n",
      "Epoch 2/200\n",
      "80/80 - 408s - loss: 1.4674 - categorical_accuracy: 0.5316 - val_loss: 2.0342 - val_categorical_accuracy: 0.4007 - lr: 1.0000e-05 - 408s/epoch - 5s/step\n",
      "Epoch 3/200\n",
      "80/80 - 399s - loss: 1.4188 - categorical_accuracy: 0.5485 - val_loss: 2.0229 - val_categorical_accuracy: 0.3997 - lr: 1.0000e-05 - 399s/epoch - 5s/step\n",
      "Epoch 4/200\n",
      "80/80 - 403s - loss: 1.3628 - categorical_accuracy: 0.5662 - val_loss: 2.0290 - val_categorical_accuracy: 0.4022 - lr: 1.0000e-05 - 403s/epoch - 5s/step\n",
      "Epoch 5/200\n",
      "80/80 - 327s - loss: 1.3190 - categorical_accuracy: 0.5826 - val_loss: 2.0430 - val_categorical_accuracy: 0.4037 - lr: 1.0000e-05 - 327s/epoch - 4s/step\n",
      "Epoch 6/200\n",
      "80/80 - 327s - loss: 1.2699 - categorical_accuracy: 0.5945 - val_loss: 2.0494 - val_categorical_accuracy: 0.4072 - lr: 1.0000e-05 - 327s/epoch - 4s/step\n",
      "Epoch 7/200\n",
      "80/80 - 329s - loss: 1.2392 - categorical_accuracy: 0.6008 - val_loss: 2.0494 - val_categorical_accuracy: 0.4087 - lr: 1.0000e-05 - 329s/epoch - 4s/step\n",
      "Epoch 8/200\n",
      "80/80 - 352s - loss: 1.1892 - categorical_accuracy: 0.6195 - val_loss: 2.0524 - val_categorical_accuracy: 0.4082 - lr: 1.0000e-05 - 352s/epoch - 4s/step\n",
      "Epoch 9/200\n",
      "80/80 - 341s - loss: 1.1407 - categorical_accuracy: 0.6321 - val_loss: 2.0677 - val_categorical_accuracy: 0.4092 - lr: 1.0000e-05 - 341s/epoch - 4s/step\n",
      "Epoch 10/200\n",
      "80/80 - 300s - loss: 1.1002 - categorical_accuracy: 0.6494 - val_loss: 2.0980 - val_categorical_accuracy: 0.4057 - lr: 1.0000e-05 - 300s/epoch - 4s/step\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d4/2tkf12c121j9pm73mz8hvsd40000gn/T/ipykernel_21247/1850580284.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m history = model.fit_generator(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0;34m'Please use `Model.fit`, which supports generators.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m         stacklevel=2)\n\u001b[0;32m-> 2016\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   2017\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1209\u001b[0m             with tf.profiler.experimental.Trace(\n\u001b[1;32m   1210\u001b[0m                 \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1248\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m       \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m       can_run_full_execution = (\n\u001b[1;32m   1252\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    643\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    647\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.adam_v2.Adam(1e-5),  # Low learning rate\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 80, \n",
    "    epochs=200,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps=40, \n",
    "    verbose=2,\n",
    "    callbacks=callbacks_list \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception 모델도 40% 이상 검증 성능 향상되지 않았다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 소규모 컨브넷 만들어보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers \n",
    "from keras import models \n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3),activation='relu', input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128, (3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128, (3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 17, 17, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               3211776   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20)                10260     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,462,868\n",
      "Trainable params: 3,462,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizers.adam_v2.Adam(learning_rate=0.001),\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 14:39:04.097210: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-02-17 14:39:04.255970: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 14:39:42.778494: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 44s - loss: 2.7822 - acc: 0.1468 - val_loss: 2.7695 - val_acc: 0.1526 - lr: 0.0010 - 44s/epoch - 545ms/step\n",
      "Epoch 2/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 42s - loss: 2.5629 - acc: 0.2141 - val_loss: 2.5590 - val_acc: 0.2226 - lr: 0.0010 - 42s/epoch - 528ms/step\n",
      "Epoch 3/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 42s - loss: 2.4609 - acc: 0.2427 - val_loss: 2.4528 - val_acc: 0.2376 - lr: 0.0010 - 42s/epoch - 531ms/step\n",
      "Epoch 4/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 42s - loss: 2.3812 - acc: 0.2669 - val_loss: 2.4346 - val_acc: 0.2441 - lr: 0.0010 - 42s/epoch - 526ms/step\n",
      "Epoch 5/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 42s - loss: 2.3176 - acc: 0.2852 - val_loss: 2.4010 - val_acc: 0.2526 - lr: 0.0010 - 42s/epoch - 529ms/step\n",
      "Epoch 6/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 46s - loss: 2.2855 - acc: 0.2966 - val_loss: 2.4305 - val_acc: 0.2611 - lr: 0.0010 - 46s/epoch - 575ms/step\n",
      "Epoch 7/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 43s - loss: 2.2281 - acc: 0.3085 - val_loss: 2.3754 - val_acc: 0.2706 - lr: 0.0010 - 43s/epoch - 540ms/step\n",
      "Epoch 8/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 46s - loss: 2.1792 - acc: 0.3288 - val_loss: 2.3344 - val_acc: 0.2801 - lr: 0.0010 - 46s/epoch - 574ms/step\n",
      "Epoch 9/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 42s - loss: 2.1337 - acc: 0.3355 - val_loss: 2.3487 - val_acc: 0.2791 - lr: 0.0010 - 42s/epoch - 530ms/step\n",
      "Epoch 10/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 42s - loss: 2.1199 - acc: 0.3462 - val_loss: 2.3451 - val_acc: 0.2891 - lr: 0.0010 - 42s/epoch - 527ms/step\n",
      "Epoch 11/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 44s - loss: 2.0614 - acc: 0.3617 - val_loss: 2.4028 - val_acc: 0.2821 - lr: 0.0010 - 44s/epoch - 547ms/step\n",
      "Epoch 12/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 43s - loss: 2.0245 - acc: 0.3708 - val_loss: 2.3161 - val_acc: 0.2931 - lr: 0.0010 - 43s/epoch - 539ms/step\n",
      "Epoch 13/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 43s - loss: 1.9851 - acc: 0.3813 - val_loss: 2.4267 - val_acc: 0.2871 - lr: 0.0010 - 43s/epoch - 537ms/step\n",
      "Epoch 14/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 45s - loss: 1.9462 - acc: 0.3835 - val_loss: 2.3736 - val_acc: 0.2821 - lr: 0.0010 - 45s/epoch - 567ms/step\n",
      "Epoch 15/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 45s - loss: 1.8946 - acc: 0.4011 - val_loss: 2.3854 - val_acc: 0.2971 - lr: 0.0010 - 45s/epoch - 557ms/step\n",
      "Epoch 16/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 42s - loss: 1.8787 - acc: 0.4042 - val_loss: 2.4779 - val_acc: 0.2726 - lr: 0.0010 - 42s/epoch - 526ms/step\n",
      "Epoch 17/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 46s - loss: 1.8107 - acc: 0.4308 - val_loss: 2.5073 - val_acc: 0.2781 - lr: 0.0010 - 46s/epoch - 581ms/step\n",
      "Epoch 18/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 46s - loss: 1.7726 - acc: 0.4455 - val_loss: 2.5557 - val_acc: 0.2681 - lr: 0.0010 - 46s/epoch - 580ms/step\n",
      "Epoch 19/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 49s - loss: 1.7166 - acc: 0.4579 - val_loss: 2.4412 - val_acc: 0.2866 - lr: 0.0010 - 49s/epoch - 606ms/step\n",
      "Epoch 20/20\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
      "80/80 - 43s - loss: 1.6860 - acc: 0.4637 - val_loss: 2.5167 - val_acc: 0.2921 - lr: 0.0010 - 43s/epoch - 543ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28a6dff40>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=80,\n",
    "    epochs=20,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps=40,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35eb7306ee2d642baa30dd47b3f48e3de4de9582bbd530539ad6f76f0b00bf2b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf25')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
