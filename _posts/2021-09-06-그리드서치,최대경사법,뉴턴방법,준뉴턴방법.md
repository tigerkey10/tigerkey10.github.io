---

---

# 최적화 

## 정의 :

함수 출력을 최대 또는 최소로 만드는 '최적 입력 찾기'

- 보통, 최적화 문제 = 최소화 문제 다. 

최대화 하고 싶은 어떤 함수 $f(x)$ 를 뒤집어서 $-f(x)$ 에 대해 최소화 문제를 풀면 결국 $f(x)$ 의 최대화 문제를 푼 것과 같다. 

$\Rightarrow$ $-f(x)$ 의 최소해는 함수 $f(x)$ 의 최대해와 같다. 

---

# 최적화 목적함수 

## 정의 : 

최적화 대상이 되는 함수를 '목적함수' 라고 한다. 

예) 성능함수, 손실함수, 오차함수, 등

---

# 최적화 방법 - 그리드 서치 방법 

## 정의 : 

최적값이 있음직한 일정 구간을 함수에 직접 넣어보는 방법.

- 직접 넣어보고 함수 출력이 최소화되는 입력값을 찾는다. 

## 특징 : 

노가다. 비효율적이다. 

특히 입력값이 많아지면 일일이 입력값-출력값 쌍을 계산해야 된다. 

## 예 : 

1차원 목적함수 최적화(최소화)

```python
def f(x) : 
    return (x-2)**2+2

xx = np.linspace(-1, 4, 1000)
plt.plot(xx, f(xx))

plt.plot(xx[np.argmin(f(xx))], f(xx)[np.argmin(f(xx))], 'ro', markersize=10)
plt.ylim(0, 10)
plt.xlabel('$x$')
plt.title('1차원 목적함수,  최적해 : $x=2$, 최저출력 : $y=2$')
plt.show()
```
<img width="707" alt="Screen Shot 2021-09-06 at 15 12 59" src="https://user-images.githubusercontent.com/83487073/132168905-a549ec35-cfc7-463f-911d-64254d92fc06.png">


### 위 그래프는 

그리드 서치 방법으로 1차원 함수 최적화 하는 과정을 시각화 한 것이다. 

$-1$, $4$ 사이 구간에서, $1000$ 개 입력값을 함수 $(x-2)^{2}+2$ 에 일일이 넣었다. 

그리고 $1000$ 개 입력에 대응되는 $1000$ 개 출력값을 하나하나 찾았다. 

그래프는 찾은 $1000$ 개 출력값들을 2차원 벡터공간 상에 일일이 점으로 찍은 것 뿐이다. 

$-1, 4$ 사이 구간 입력 $1000$ 개를 넣어 본 결과, $x=2$ 에서 가장 출력값이 작았다. 

따라서 함수 출력을 최소화 하는 최적 입력값은 $x=2$ 이다. 

---

# 최적화 방법 - 수치적 최적화 방법 

## 정의 : 

최소 시도 횟수로 최적화를 성공시키고자 하는 게 목표인 최적화 방법. 

## 수치적 최적화 알고리듬 : 

1. 현재 위치가 최적점(최소점) 인지 판단하는 알고리듬
2. 현재 위치가 최적점이 아닐 때, 옮겨 갈 다음 위치를 선정하는 알고리듬 

# 기울기 필요조건 (최적화 필요조건)

## 정의 : 

최적해에서, 1차 도함숫값(기울기)은 0이다. 

- 최소해. 최대해 모두 1차 도함숫값이 0 나와야 한다.
- 2차 도함숫값이 양수면 확실한 최소점
- 2차 도함숫값이 음수면 확실한 최대점이다. 

## 현재 위치가 최적점인지 판단하는 알고리듬 이다. 

# 최대경사법(최급강하법)

현재 위치가 최적점이 아닐 때, 옮겨 갈 다음 위치를 선정하는 알고리듬이다. 

## 정의 : 

기울기가 가장 크게 감소하는 방향으로 이동하는 수치적 최적화 알고리듬. 

## $x_{n+1} = x_{n} - \mu\nabla{f(x_{n})}$

- $\mu$ 는 '스텝사이즈'라고 한다. 위치 얼만큼 이동할 건지 거리를 결정짓는다. 

### 단변수 함수 

- $-\mu$ $\times$ $\nabla{f(x_{n})}$ 만큼 $x$ 축 따라 계속 이동하다가, $x_{n+1} = x_{n}$ 이 되면(기울기가 $0$ 되면) 이동 멈춘다.

### 다변수 함수 

- 각 점의 그레디언트 벡터 반대방향(지름길)으로 $- \mu\nabla{f(x_{n})}$ 벡터의 길이만큼 이동한다. 
- 다음 













