---
title : "[Keras/딥러닝 공부] 머신러닝 기법 분류, 데이터셋 분리 기법, 데이터 전처리 기법"
excerpt : "공부한 내용을 기록한 글"

categories : 
- Data Science
- python
- Keras 
- deep learning

tags : 
- [data science, python, keras, deep learning]

toc : true 
toc_sticky : true 
use_math : true

date : 2022-02-04
last_modified_at : 2022-02-04

---

아래 내용은 '케라스 창시자에게 배우는 딥러닝 (프랑소와 슐레 저, 박해선 옮김, 길벗 출판사)' 을 공부한 뒤, 배운 내용을 제 언어로 정리.기록한 것 입니다. 

---

# 머신러닝 네 가지 분류 

## 지도 학습 

### 정의 
사람이 정답 주고, 모델이 주어진 정답 잘 맞추도록 학습시키는 기법 

### 종류
- 분류
- 회귀
- 시퀀스 생성 
- 구문 트리 예측 
- 물체 감지
- 이미지 분할 

---

## 비지도 학습 

### 정의 
데이터 자체의 특성 파악. 추출하도록 학습시키는 기법 

### 종류 
- 차원 축소 
- 군집(Clustering)

---

## 자기 지도 학습 

### 정의 
사람이 개입하지 않는 지도학습 

- 모형이 경험적 알고리듬(heuristic algorithm) 사용해 입력 데이터로부터 레이블 생성한다. 

### 종류 
- 오토인코더(autoencoder)
- 시간에 따른 지도 학습 

---

## 강화학습 

## 정의 
모형이 주어진 상황에서 보상 강화하는 출력을 선택하도록 학습시키는 기법 

- 아직 현장에서는 잘 사용되지 않고, 연구 영역에 있다. 
- 하지만 발전 가능성, 비전 있는 머신러닝 분야다. 

## 예
게임에서 강화학습 

- 게임 속 전장 상황이 주어지면, 모형이 게임 점수 최대화 할 수 있는 게임 내 행동을 출력

---

# 머신러닝 모델 평가 

'일반화 할 수 있는 모델 평가'

$\Rightarrow$ 새 데이터셋에서 모델 성능 평가 

- 모델 성능 평가 위해 '신뢰할 수 있는 모델 성능 측정 방법'이 필요하다. 

---

# 데이터셋을 훈련용, 검증용, 테스트용 셋으로 나누기 

## 모델 훈련시키고 성능 평가하는 과정 

- 훈련용 셋에서 모델을 훈련시킨다.
- 검증용 셋으로 새 데이터셋에서 모델 성능 평가한다.
- 검증용 셋 결과 가지고. 신경망 각 층의 히든유닛 수, 층 수 등 하이퍼파라미터 '튜닝'한다. 모델 성능 올리기 위한 작업이다. 
- 튜닝된 모델을 다시 훈련용 셋으로 훈련시키고, 성능 검증하고, 튜닝한다. 
- 튜닝 모두 끝나면 테스트용 셋으로 딱 한 번 모델 성능 평가한다. 

## 테스트용 셋 따로 두는 이유 

과정 중 하이퍼파라미터 튜닝 반복하면서 모델이 검증용 셋에 과적합 되는 경향 나타난다. 

따라서 튜닝 반복하다 보면 검증용 셋에서 성능이 갈수록 올라갈 수 밖에 없다. 

새 데이터셋에서 모델 성능 제대로 평가하기 위해 완전히 새로운 데이터가 필요하고, 그 역할 하는 게 테스트 셋이다.


# 데이터셋 나누는 기법


## 단순 홀드아웃 검증 

Hold out: 남겨두다 

## 정의 

전체 셋에서 검증용 셋 따로 떼어두는 방법 

- 테스트용 셋은 검증용 셋 분리 전에 따로 떼 두었다고 가정

<img width="519" alt="Screen Shot 2022-02-04 at 11 25 50" src="https://user-images.githubusercontent.com/83487073/152462213-cb66331b-58d2-4529-a5ac-aef2d5ca2f77.png">

- 훈련용 셋으로 모델 훈련시킨다
- 검증 셋으로 모델 성능 검증하고, 하이퍼파라미터 튜닝한다

## 장점 

단순하다. 복잡한 작업 필요 없다. 

## 단점 

데이터 적으면 훈련용 셋과 검증용 셋의 전체 데이터에 대한 통계적 대표성 떨어진다. 

$\Rightarrow$ 데이터 수 적을 때는 적용할 수 없다. 

## K-겹 교차검증 

데이터 수 작을 때 특히 유용한 방법이다. 

## 정의 

전체 데이터셋 k개 분할로 나눠 그 중 하나는 검증용 셋, 나머지는 훈련용 셋으로 삼는 방법 

- 모델 훈련 - 검증 과정 k번 반복한다. 
- k개 성능 점수 평균을 최종 성능 점수로 삼는다. 

<img width="934" alt="Screen Shot 2022-02-04 at 12 32 58" src="https://user-images.githubusercontent.com/83487073/152467557-0862f6ed-0e54-453d-a210-a4c68d91d0cc.png">

## 셔플링 사용한 반복 K-겹 교차검증 

데이터 수 작을 때 특히 유용한 방법이다. 

## 정의 

P번 반복해서 K-겹 교차검증 수행

- K-겹 교차검증 수행 하기 전 매번 데이터셋 무작위로 섞는다(셔플)
- P번의 K-겹 교차검증 점수 평균이 최종 점수 된다. 

## 단점

시간 많이 걸린다. 

---

# 이외 기억해야 할 점 

- 데이터셋을 훈련용 셋, 검증용 셋, 테스트 셋으로 나누기 전에 되도록 데이터셋 한번 섞자(셔플).

```python 
# 셔플 

np.random.shuffle(data)
```

- 데이터에 시간 순서가 나타나면 절대 섞으면 안 된다. 훈련용 셋은 상대적으로 과거 데이터, 테스트 셋은 상대적으로 미래 데이터로 구성되도록 분리하자. 

- 데이터셋에 중복된 데이터(레코드)가 있으면 제거하는 것이 좋다. 

---

# 데이터 전처리 

데이터 전처리 기법들은 입력 데이터 종류별로 특화되어 있다. 예컨대 이미지, 텍스트 데이터 전처리 방법이 다르다. 

# 신경망 위한 데이터 전처리 일반론

## 벡터화(데이터 벡터화)

### 정의 

입력 데이터를 부동 소수점 실수 또는 정수로 구성된 텐서로 변환하는 작업. 

- 신경망 모든 입력은 텐서여야 하므로, 데이터 전처리 할 때 반드시 거치는 과정이다. 

---

## 정규화 

### 정의 

각 데이터를 0과 1 사이(또는 작은 값) 로 변환하고, 특성값들 간 스케일 맞춰주는 작업이다. 

- 신경망의 원활한 학습 위해 반드시 거쳐야 할 과정이다. 

## 보다 엄격한 정규화(수학적 정규화)

### 정의 

각 특성 별 데이터를 평균이 0, 표준편차가 1로 만드는 작업. 

---

## 누락된 값(Null/NA) 값 다루기 

전체 평균에 영향 미치지 않는 값으로 누락된 값 채운다. 

## Null 자리에 뭘 넣는가

- 일반적으로 0 넣는다. 
- 평균값을 넣기도 한다. 
- 중앙값을 넣기도 한다. 

만약 훈련용 셋 누락 값을 그 평균. 중앙값으로 대체하기로 했다면, 

테스트 셋 누락 값도 훈련용 셋 평균. 중앙값으로 대체해야 한다. 

교차검증 할 때도 검증용 셋 누락 값은 훈련용 셋 평균. 중앙값으로 채워야 한다. 

## 만약 훈련용 셋에 누락 값 없는데 테스트셋에 있다면? 

모델이 훈련 받을 때 누락 값 처리 방법을 학습하지 못했으므로, 문제 발생한다. 

## 따라서 

- 전체 데이터셋에서 누락 값 있는 샘플(레코드 or 행벡터) 수가 적다면, 테스트셋 떼어놓기 전 이 레코드들 제외한다. 
- 누락된 값 있는 특성이 별로 안 중요하면, 이 특성을 통째로 제외하고 테스트셋 떼어 놓는다. 

---

## 특성 공학 

### 정의 

원본 데이터에서 특성만 추출해서 데이터 변환하는 작업. 

- 문제에 대한 명료한 정의를 내릴 수 있어야 한다. 

### 예시 

시계 사진(이미지) 에 나타난 시간 정보 출력하는 모형 만들고 싶다. 

- 시계 사진 그대로 써서 정보 추출하기에는 보다 복잡한 모형, 높은 컴퓨팅 파워 필요하다. 

한편 시계 사진 데이터에 특성 공학 적용하면 아래와 같아진다. 

내가 추출하고 싶은 정보는 '시간 정보'다. 

그러면 굳이 원본 데이터 전체가 필요 없다. 시간 정보만 있으면 된다. 

### $\Rightarrow$ 원본 데이터에서 시간 정보 나타내는 특성만 추출한다. 

여기서 '시간'에 대한 정의가 필요하다. 

### 시간 정의: 초침과 분침이 가리키는 지점. 

$\Rightarrow$ 원본 데이터에서 초침과 분침이 가리키는 지점 정보만 추출한다. 


또는 

### 시간 정의: 초침과 분침이 이루는 각도. 

$\Rightarrow$ 원본 데이터에서 초침과 분침이 이루는 각도 정보만 추출한다. 

### 결과로 

2차원 벡터공간 상의 특정 지점(point) 

또는 

원점과 2차원 직교좌표계를 중심으로 한 어떤 각도 값들로 

구성된 1차원 텐서(벡터)가 나올 것이다. 

이 벡터가 원본 이미지 데이터가 '변환된' 데이터 이고, 이렇게 원본 데이터 변환하는 작업을 '특성 공학' 이라 한다. 

### 쓰임

- 특성 공학은 전통적 머신러닝 기법들 사용할 때 아주 중요하게 쓰인다. 
- 딥러닝 기법 사용할 때는 특성 공학 필요 없다. 

### 그럼에도 

- 특성 공학 사용하면. 딥러닝 모델 썼을 때 보다. 특정 문제를 더 적은 자원 & 훨씬 효율적으로 해결할 수 있다. 위 시계 문제가 예다. 
- 데이터 수 적어서 딥러닝 모델 적용할 수 없을 때. 특성 공학 사용하면 적은 데이터로 문제 효과적으로 해결할 수 있다. 

---

# 과대적합과 과소적합 

## 머신러닝 근본 이슈는 '일반화'와 '최적화' 사이 줄다리기 

최적화는 '훈련 데이터'에서 모델 성능 최대화 하기 위해 최적 파라미터 찾는 작업 말한다. 

일반화는 '새 데이터'에서 모델 성능이 잘 나오도록 하는 걸 말한다. 

최적화가 과도하면 과대적합 나타난다. 모델 일반화 성능은 떨어진다. 

반면 최적화 부족하면 과소적합 나타난다. 모델 일반화 성능 더 끌어올릴 여지 남아있다. 


## 과대적합(Overfitting)

모든 머신러닝 문제에서 과대적합은 종종.자주. 마주치는 문제다. 

따라서 머신러닝에서는 과대적합 잘 제어하는 것이 중요하다. 

## 정의 

모델이 학습 데이터에 특화된 패턴을 학습하기 시작한 상태.

### $\Rightarrow$ 모델이 학습 데이터와 레이블을 '외워버리기 시작한' 상태. 

## 과대적합 있을 때 모델 성능

과대적합이 나타나면 검증용 셋에서 모델 성능은 떨어지기 시작한다. 

테스트 셋에서도 모델 성능이 낮게 나온다. 곧, 과대적합 나타나면 모델 일반화 성능 떨어진다. 

## 과소적합(Underfitting)

모델 훈련 초기에 나타난다. 

## 정의

모델이 훈련 데이터에 나타난 특징들을 아직 충분히(모두) 학습하지 못한 상태. 

## 과소적합 있을 때 모델 성능 

과소적합 있을 때, 모델 성능은 훈련용 셋과 검증용 셋 모두에서 함께 증가한다. 

과소적합 있을 때는 모델 성능이 아직 더 향상될 여지가 남아있다. 

- 과소적합 상태 끝나고나면 곧이어 과대적합 나타나기 시작한다. 

---

# 규제(Regularization)

## 정의 

모델에 과대적합 발생 억제하는 과정 

- 모델에 과대적합 발생하면 모델 일반화 성능(모델 개발 목표)이 떨어진다. 그래서 규제 통해 과대적합 발생 억제한다. 

## 종류 

### 더 많은 훈련 데이터 모으기 

과대적합 억제하는 가장 좋은 방법이다. 훈련 데이터가 많으면 많을 수록. 과대적합 발생 억제되고, 모델 일반화 성능도 올라간다. 

### 모델이 수용할 수 있는 정보량 조절하기 & 모델이 제한적 정보만 저장하게 하기 

차선책. 모델이 적은 수 패턴만 기억할 수 있게 되면서, 훈련 데이터 패턴 중 가장 중요한 패턴에 집중하게 된다. 결과로 과대적합은 피하고, 일반화 성능은 향상된다. 

# 신경망 크기 축소 

규제 기법 중 하나다. 




























